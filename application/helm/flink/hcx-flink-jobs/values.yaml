namespace: flink
imagePullSecrets: []
dockerhub: "maheshkg"
repository: "hcx-flink-jobs"
image_tag: "latest"
serviceMonitor:
  enabled: false
replicaCount: 1

job_classname: "org.swasth.dp.coverageeligiblitycheck.task.CoverageEligibilityCheckStreamTask"

taskManagerAdditionalArgs: []
  # For example
  # - -Dfs.azure.account.key.{{ .Values.azure_account }}.blob.core.windows.net={{ .Values.azure_secret }},
jobManagerAdditionalArgs: []
  # For example
  # - -Dfs.azure.account.key.hcxapi.blob.core.windows.net=mysupersecretpassword

jobmanager:
  rpc_port: "6123"
  blob_port: "6124"
  query_port: "6125"
  ui_port: "8081"
  prom_port: "9250"
  heap_memory: "1024"

service:
  type: LoadBalancer
  # If you want a private LB in azure, add the following
  # annotations:
  #   service.beta.kubernetes.io/azure-load-balancer-internal: "true"
  
rest_port: "80"
resttcp_port: "8081"

taskmanager:
  prom_port: 9251
  rpc_port: 6122
  heap_memory: 1024
  replicas: 1

healthcheck: true
taskmanager_liveness:
  livenessProbe:
    tcpSocket:
      port: 6122
    initialDelaySeconds: 30
    periodSeconds: 60

log4j_console_properties: |
  # This affects logging for both user code and Flink
  rootLogger.level = "INFO"
  rootLogger.appenderRef.console.ref = ConsoleAppender

  # Uncomment this if you want to _only_ change Flink's logging
  #logger.flink.name = org.apache.flink
  #logger.flink.level = {{ flink_jobs_console_log_level | default(INFO) }}

  # The following lines keep the log level of common libraries/connectors on
  # log level INFO. The root logger does not override this. You have to manually
  # change the log levels here.
  logger.akka.name = akka
  logger.akka.level = "INFO"
  logger.kafka.name= org.apache.kafka
  logger.kafka.level = "INFO"
  logger.hadoop.name = org.apache.hadoop
  logger.hadoop.level = "INFO"
  logger.zookeeper.name = org.apache.zookeeper
  logger.zookeeper.level = "INFO"

  # Log all infos to the console
  appender.console.name = ConsoleAppender
  appender.console.type = CONSOLE
  appender.console.layout.type = PatternLayout
  appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

  # Suppress the irrelevant (wrong) warnings from the Netty channel handler
  logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
  logger.netty.level = OFF

base_config: |
  kafka {
      broker-servers = "10.0.1.196:9092"
      zookeeper = "10.0.1.196:2181"
      producer {
        max-request-size = 1572864
      }
    }
    job {
      env = "dev"
      enable.distributed.checkpointing = false
      statebackend {
        blob {
          storage {
            account = "local.blob.core.windows.net"
            container = "local"
            checkpointing.dir = "checkpoint"
          }
        }
        base.url = "wasbs://"${job.statebackend.blob.storage.container}"@"${job.statebackend.blob.storage.account}"/"${job.statebackend.blob.storage.checkpointing.dir}
      }
    }
    task {
      parallelism = 1
      consumer.parallelism = 1
      checkpointing.compressed = true
      checkpointing.interval = 60000
      checkpointing.pause.between.seconds = 30000
      restart-strategy.attempts = 3
      restart-strategy.delay = 30000
    }
    postgres {
      host = localhost
      port = 5432
      maxConnections = 2
      user = "postgres"
      password = "password"
    }
    redis {
      host = redis-master.dev.svc.cluster.local
      port = 6379
    }
    redisdb{
      connection {
        timeout: 30000
        }
      }
    redis-meta {
      host = redis-master.dev.svc.cluster.local
      port = 6379
    }
    lms-cassandra {
      host = "localhost"
      port = "9042"
    }

eligibilitycheck:
  eligibilitycheck: |+
    include file("/data/flink/conf/base-config.conf")
    kafka.groupId:  ${job.env}"-coverage-eligibility-check-group"
    kafka.input.topic: dev.hcx.request.eligibilitycheck
    kafka.audit.topic: dev.hcx.audit
    kafka.retry.topic: dev.hcx.request.retry
    task.consumer.parallelism :  1
    task.parallelism :  1
    task.downstream.operators.parallelism: 1
    #Postgres
    postgres.database: hcx_db
    postgres.table: payload
    #Registry
    service.registry.basePath: "http://localhost:8081"
    kafka.producer.max-request-size: 1572864
    kafka.producer.batch.size: 98304
    kafka.producer.linger.ms: 10

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
